{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as ps\n",
    "import geopandas as gpd\n",
    "import splot\n",
    "import matplotlib.pyplot as plt\n",
    "import esda\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sqlite3 as sq\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "conn = sq.connect('/home/manuel/Desktop/pROYECTO/database.db')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seleccion = pd.read_sql('SELECT * FROM Seleccionados', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['P6040', 'P8586', 'P6211', 'P6240', 'P6020', 'P6435', 'P6440',\n",
       "       'P6460S1', 'P8636', 'P8654', 'NOMB_DEP', 'CANT_PERSONAS_HOGAR',\n",
       "       'DIRECTORIO', 'MPIO', 'NOMB_MUN', 'COD_MPIO', 'LATITUD', 'LONGITUD',\n",
       "       'Total_ingresos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seleccion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/Desktop/pROYECTO/.venv/lib/python3.8/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The identity link alias is deprecated. Use Identity instead. The identity link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n",
      "/home/manuel/Desktop/pROYECTO/.venv/lib/python3.8/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The inverse_power link alias is deprecated. Use InversePower instead. The inverse_power link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC modelo 1 -38580.8 vs BIC modelo 2 -18789.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/Desktop/pROYECTO/.venv/lib/python3.8/site-packages/statsmodels/genmod/generalized_linear_model.py:1923: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODELO LINEAL GENERALIZADO\n",
    "data_model  = seleccion[['P6260','P6460','CANT_PERSONAS_HOGAR','P3193S3','P6020','P6040','P6087','P6240','P6390S2','P6435',\n",
    "                       'P6440','P6460S1','P7250','P8587','P8634','P8636','P8654','Total_ingresos']]\n",
    "\n",
    "X = data_model.drop(columns = ['Total_ingresos'])\n",
    "y = data_model['Total_ingresos']\n",
    "\n",
    "familia = sm.families.Gaussian\n",
    "funcion_enalce = sm.families.links.identity()\n",
    "\n",
    "modelo1 = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "resultados = modelo1.fit()\n",
    "\n",
    "# MODELO 2 LINEAL GENERALIZADO\n",
    "data_model  = seleccion[['P6260','P6460','CANT_PERSONAS_HOGAR','P3193S3','P6020','P6040','P6087','P6240','P6390S2','P6435',\n",
    "                       'P6440','P6460S1','P7250','P8587','P8634','P8636','P8654','Total_ingresos']]\n",
    "\n",
    "X = data_model.drop(columns = ['Total_ingresos'])\n",
    "y = data_model['Total_ingresos']\n",
    "\n",
    "familia = sm.families.Gaussian\n",
    "funcion_enalce = sm.families.links.inverse_power()\n",
    "\n",
    "modelo2 = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "resultados2 = modelo2.fit()\n",
    "# BIC\n",
    "\n",
    "print(f'BIC modelo 1 {resultados.bic:.1f} vs BIC modelo 2 {resultados2.bic:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se evalua la normalidad en la variable de respuesta\n",
    "\n",
    "st_pagos = stats.shapiro(seleccion['Total_ingresos'])\n",
    "\n",
    "if st_pagos.pvalue > 0.05:\n",
    "    print(f'Se acepta la hipótesis nula, con un valor p de {st_pagos.pvalue:.2f}')\n",
    "else:\n",
    "    print(f'Se rechaza la hipótesis nula, con un valor p de {st_pagos.pvalue:.2f}')\n",
    "\n",
    "# TABLA RESUMEN DE LOS INGRESOS TOTALES\n",
    "seleccion[['Total_ingresos']].describe().to_latex()\n",
    "\n",
    "# TABLA RESUMEND E INGRESOS TOTALLES POR DEPARTAMENTO\n",
    "resumen_mun = seleccion.groupby('NOMB_MUN').agg({\n",
    "    'Total_ingresos': ['mean', 'std', 'count']\n",
    "})\n",
    "\n",
    "resumen_mun.to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as ps\n",
    "from esda import Moran, Moran_Local\n",
    "\n",
    "# ESTA ES LA BASE CON QUE SE REALIZA LOS GRAFICOS Y LOS ESTUDIOS DE DEPENDENCIA ESPACIAL\n",
    "cart = seleccion.groupby(['NOMB_MUN','COD_MPIO','LATITUD','LONGITUD']).agg(MEDIA = ('Total_ingresos','mean')).reset_index()\n",
    "\n",
    "gdf = gpd.read_file('Mapas/Municipio, Distrito y Area no municipalizada.shp')\n",
    "gdf = gdf[gdf['Depto'] == 'Cundinamarca']\n",
    "\n",
    "gdf['MpCodigo'] = pd.to_numeric(gdf['MpCodigo'], errors='coerce')\n",
    "df_ = gdf.merge(cart,left_on='MpCodigo', right_on='COD_MPIO', how='inner')\n",
    "\n",
    "\n",
    "# GRAFICO DE LOS INGRESOS PROMEDIOS POR MUNICIPIO\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "gdf.plot(ax=ax, color='white', edgecolor='black')\n",
    "df_.plot(column='MEDIA', ax=ax, legend=True,edgecolor='black',\n",
    "         legend_kwds={'label': \"MEDIA\",\n",
    "                      'orientation': \"vertical\"})\n",
    "plt.title(\"INGRESOS MEDIOS CUNDINAMARCA\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq =  ps.weights.Queen.from_dataframe(df_)\n",
    "wq.transform = 'r'\n",
    "\n",
    "moran = Moran(df_['MEDIA'],wq)\n",
    "\n",
    "print(f'El indice de Morgan General es de : {moran.I:.2f}')\n",
    "print(f'El valor p para el sistema de hipótesis es de {moran.p_sim}') # si hay diferencia espacial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if moran.p_sim < 0.05:\n",
    "    print(f'Con un valor de {moran.p_sim:.3f}, se rechaza la hipótesis nula H0: I=0. Entonces, existe dependencia espacial.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el índice de Moran Local para la variable 'MEDIA'\n",
    "ml = esda.Moran_Local(df_['MEDIA'], wq)\n",
    "\n",
    "# Acceder a los valores p de la simulación\n",
    "p_values = ml.p_sim\n",
    "\n",
    "# Asumiendo que ya tienes el GeoDataFrame df_ con los resultados de Moran's I Local\n",
    "df_['moran_local'] = ml.p_sim  # Añadir el resultado de Moran's I Local al GeoDataFrame\n",
    "\n",
    "# Graficar en el mapa\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "gdf.plot(ax=ax, color='white', edgecolor='black')\n",
    "df_.plot(column='moran_local', ax=ax, legend=True,edgecolor='black',\n",
    "         legend_kwds={'label': \"Moran's I Local\",\n",
    "                      'orientation': \"horizontal\"})\n",
    "plt.title(\"Mapa de Moran's I Local\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/Desktop/pROYECTO/.venv/lib/python3.8/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The inverse_power link alias is deprecated. Use InversePower instead. The inverse_power link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC modelo 1 -18789.5 vs BIC modelo 2 -18607.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/Desktop/pROYECTO/.venv/lib/python3.8/site-packages/statsmodels/genmod/generalized_linear_model.py:1923: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODELO 3 LINEAL GENERALIZADO\n",
    "data_model  = seleccion[['P6260','P6460','CANT_PERSONAS_HOGAR','P3193S3','P6020','P6040','P6087','P6240','P6390S2','P6435',\n",
    "                       'P6440','P6460S1','P7250','P8587','P8634','P8636','P8654','Total_ingresos','LATITUD','LONGITUD']]\n",
    "\n",
    "X = data_model.drop(columns = ['Total_ingresos'])\n",
    "y = data_model['Total_ingresos']\n",
    "\n",
    "familia = sm.families.Gaussian\n",
    "funcion_enalce = sm.families.links.inverse_power()\n",
    "\n",
    "modelo3 = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "resultados3 = modelo3.fit()\n",
    "\n",
    "# resultados3.summary()\n",
    "\n",
    "print(f'BIC modelo 2 {resultados2.bic:.1f} vs BIC modelo 3 {resultados3.bic:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO DE REGRESION LINEAL GENERALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = seleccion[[ 'P6020', 'P6040', 'P6087', 'P6160','P8586', 'P8587', 'P6211', 'P1088', 'P6216', 'P5673', 'P6240', 'P6250',\n",
    "            'P6260', 'P6280', 'P6370S2', 'P6390S2', 'P6435', 'P6440', 'P6450','P6460', 'P6460S1', 'P8632', 'P8634',\n",
    "            'P3193S3', 'P8636', 'P7250','P7270S2', 'P8654', 'CANT_PERSONAS_HOGAR','Total_ingresos']]\n",
    "\n",
    "X = df_model.drop(columns = ['Total_ingresos'])\n",
    "y = df_model['Total_ingresos']\n",
    "\n",
    "familia = sm.families.Gaussian\n",
    "funcion_enalce = sm.families.links.identity()\n",
    "\n",
    "modelo1 = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "resultados = modelo1.fit()\n",
    "# VARIABLES NO SIGNIFICATIVAS PARA EL MODELO\n",
    "n_sg = resultados.pvalues[resultados.pvalues > 0.05]\n",
    "\n",
    "#VARIABLES SIGNIFICAIVAS PARA EL MODELO\n",
    "sg = resultados.pvalues[resultados.pvalues <= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultados.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preparar los datos\n",
    "df_model = seleccion[['P6020', 'P6040', 'P6087', 'P6160', 'P8586', 'P8587', 'P6211', 'P1088', 'P6216', 'P5673', \n",
    "                      'P6240', 'P6250', 'P6260', 'P6280', 'P6370S2', 'P6390S2', 'P6435', 'P6440', 'P6450', \n",
    "                      'P6460', 'P6460S1', 'P8632', 'P8634', 'P3193S3', 'P8636', 'P7250', 'P7270S2', 'P8654', \n",
    "                      'CANT_PERSONAS_HOGAR', 'Total_ingresos']]\n",
    "\n",
    "X = df_model.drop(columns=['Total_ingresos'])\n",
    "y = df_model['Total_ingresos']\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular las métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model[sg.index]\n",
    "y = y \n",
    "\n",
    "modelo2 = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "resultados2 = modelo2.fit()\n",
    "\n",
    "resultados2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ajustar_y_evaluar(X, y, distribucion='Gaussian', enlace='identity'):\n",
    "    # Ajuste del modelo GLM\n",
    "#    familia = getattr(sm.families, distribucion)()\n",
    "    familia = sm.families.Gaussian\n",
    "#    funcion_enlace = getattr(sm.families.links, enlace)()\n",
    "    funcion_enalce = sm.families.links.Identity\n",
    "    modelo = sm.GLM(y, X, family=familia(link=funcion_enalce))\n",
    "    resultados = modelo.fit()\n",
    "\n",
    "    # Evaluación de supuestos\n",
    "    residuos = resultados.resid_response\n",
    "    \n",
    "    # Residuos vs valores ajustados (homocedasticidad)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(resultados.fittedvalues, residuos)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Valores Ajustados')\n",
    "    plt.ylabel('Residuos')\n",
    "    \n",
    "    # Histograma de residuos (normalidad)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(residuos, kde=True, color='blue')\n",
    "    plt.title('Distribución de Residuos')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Prueba de Shapiro-Wilk (normalidad)\n",
    "    shapiro_test = stats.shapiro(residuos)\n",
    "    print(f\"Prueba Shapiro-Wilk: Estadístico = {shapiro_test.statistic}, p-value = {shapiro_test.pvalue}\")\n",
    "\n",
    "    # Prueba de Breusch-Pagan (heterocedasticidad)\n",
    "    X_const = add_constant(X)\n",
    "    bp_test = het_breuschpagan(residuos, X_const)\n",
    "    print(f\"Prueba Breusch-Pagan: Estadístico = {bp_test[0]}, p-value = {bp_test[1]}\")\n",
    "\n",
    "    # VIF (multicolinealidad)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_const.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "    print(vif_data)\n",
    "\n",
    "    # Durbin-Watson (autocorrelación)\n",
    "    dw_stat = sm.stats.durbin_watson(residuos)\n",
    "    print(f\"Estadístico Durbin-Watson: {dw_stat}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Ejemplo de uso\n",
    "X = df_model[['P6020', 'P6040', 'P6087', 'P6160', 'P8586', 'P8587', 'P6211', 'P1088', 'P6216', 'P5673', 'P6240', 'P6250', 'P6260', 'P6280', 'P6370S2', 'P6390S2', 'P6435', 'P6440', 'P6450', 'P6460', 'P6460S1', 'P8632', 'P8634', 'P3193S3', 'P8636', 'P7250', 'P7270S2', 'P8654', 'CANT_PERSONAS_HOGAR']]\n",
    "y = df_model['Total_ingresos']\n",
    "\n",
    "resultados = ajustar_y_evaluar(X, y, distribucion='Gaussian', enlace='identity')\n",
    "print(resultados.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO CON LA GAUSSIANA FUNCION DE IDENTIDAD IDENTIDAD\n",
    "\n",
    "X = df_model[['P6020', 'P6040', 'P6087', 'P6160', 'P8586', 'P8587', 'P6211', 'P1088',\n",
    "       'P6216', 'P5673', 'P6240', 'P6250', 'P6260', 'P6280', 'P6370S2',\n",
    "       'P6390S2', 'P6435', 'P6440', 'P6450', 'P6460', 'P6460S1', 'P8632',\n",
    "       'P8634', 'P3193S3', 'P8636', 'P7250', 'P7270S2', 'P8654',\n",
    "       'CANT_PERSONAS_HOGAR']]\n",
    "\n",
    "y = df_model.loc[:,'Total_ingresos']\n",
    "\n",
    "normal_model = sm.GLM(y, X, family=sm.families.Gaussian(link=sm.families.links.Identity()))\n",
    "normal_results =  normal_model.fit()\n",
    "print(normal_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from scipy import stats\n",
    "\n",
    "def evaluar_supositos_glm(normal_results, X, y):\n",
    "    # Usar los residuos de Pearson\n",
    "    residuos = normal_results.resid_pearson\n",
    "    \n",
    "    # 1. Prueba de Shapiro-Wilk (Normalidad)\n",
    "    shapiro_test = stats.shapiro(residuos)\n",
    "    print(f\"Prueba Shapiro-Wilk: Estadístico = {shapiro_test.statistic}, p-value = {shapiro_test.pvalue}\")\n",
    "    if shapiro_test.pvalue < 0.05:\n",
    "        print(\"Se rechaza la hipótesis nula: Los residuos no siguen una distribución normal.\")\n",
    "    else:\n",
    "        print(\"No se rechaza la hipótesis nula: Los residuos siguen una distribución normal.\")\n",
    "    \n",
    "    # 2. Prueba de Breusch-Pagan (Heterocedasticidad)\n",
    "    X_const = add_constant(X)  # Agregar constante (intercepto)\n",
    "    bp_test = het_breuschpagan(residuos, X_const)\n",
    "    print(f\"Prueba Breusch-Pagan: Estadístico = {bp_test[0]}, p-value = {bp_test[1]}\")\n",
    "    if bp_test[1] < 0.05:\n",
    "        print(\"Se rechaza la hipótesis nula: Hay heterocedasticidad (varianza no constante de los residuos).\")\n",
    "    else:\n",
    "        print(\"No se rechaza la hipótesis nula: No hay evidencia de heterocedasticidad.\")\n",
    "    \n",
    "    # 3. Multicolinealidad (VIF)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X_const.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "    print(\"VIF de las variables:\")\n",
    "    print(vif_data)\n",
    "    if any(vif_data[\"VIF\"] > 10):\n",
    "        print(\"Se rechaza la hipótesis nula: Hay multicolinealidad en el modelo.\")\n",
    "    else:\n",
    "        print(\"No se rechaza la hipótesis nula: No hay problemas de multicolinealidad.\")\n",
    "    \n",
    "    # 4. Durbin-Watson (Autocorrelación)\n",
    "    dw_stat = sm.stats.durbin_watson(residuos)\n",
    "    print(f\"Estadístico Durbin-Watson: {dw_stat}\")\n",
    "    if dw_stat < 1.5 or dw_stat > 2.5:\n",
    "        print(\"Se rechaza la hipótesis nula: Hay autocorrelación en los residuos.\")\n",
    "    else:\n",
    "        print(\"No se rechaza la hipótesis nula: No hay autocorrelación en los residuos.\")\n",
    "\n",
    "\n",
    "normal_results = normal_model.fit()\n",
    "\n",
    "# Evaluar los supuestos\n",
    "evaluar_supositos_glm(normal_results, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Modelo original\n",
    "model_original = LinearRegression()\n",
    "score_original = cross_val_score(model_original, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Modelo original - Validación cruzada: {-score_original.mean()}\")\n",
    "\n",
    "# Modelo reducido\n",
    "model_reducido = LinearRegression()\n",
    "score_reducido = cross_val_score(model_reducido, X_reducido, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Modelo reducido - Validación cruzada: {-score_reducido.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO ORIGINAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
